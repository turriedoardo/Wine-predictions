{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importo le librerie\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn import datasets\n",
    "from scipy.stats import poisson, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbene\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carico il dataset dividendo tra features e labels\n",
    "features, target = datasets.load_wine(return_X_y = True, as_frame = True)\n",
    "\"\"\"\n",
    "bene\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "..                            ...      ...  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "173    2\n",
       "174    2\n",
       "175    2\n",
       "176    2\n",
       "177    2\n",
       "Name: target, Length: 178, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stampo matrice delle features\n",
    "display(features)\n",
    "# stampo vettore target\n",
    "display(target)\n",
    "\n",
    "# mostro quante sono le possibili labels\n",
    "pd.unique(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divido in training set e test set, utilizzando il 30% dei dati per il test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "decision tree ha almeno un iperparametro importante, che dovrebbe essere validato\n",
    "\n",
    "la profondità(?)\n",
    "---\n",
    "yep\n",
    "---\n",
    "\n",
    "gli iperparametri di un modello cambiano completamente le sue performance,\n",
    "e non è detto che un primo addestramento con dei valori di default ne diano un'idea ragionevole\n",
    "\n",
    "prima di cambiare modello, prova a validare gli iperparametri di DT\n",
    "\n",
    "quali sono? che effetto hanno sul fitting dei dati?\n",
    "\n",
    "La profondità (max_depth) indica quanto sarà esteso l'albero,\n",
    "cioè il numero di nodi per ogni decisione.\n",
    "---\n",
    "il numero massimo di nodi di una decisione, cioè la lunghezza massima\n",
    "del percorso tra la radice e una foglia; che effetto ha sull'addestramento?\n",
    "a cosa corrisponde una profondità alta? e una bassa?\n",
    "---\n",
    "\n",
    "min_sample_leaf indica il numero minimo di esempi necessari perchè ci si trovi in una foglia\n",
    "---\n",
    "il numero minimo di esempi che può avere una foglia; questo evita di splittare ulteriormente\n",
    "nodi con troppi pochi esempi; che effetto ha? a cosa corrispondono valori alti o bassi?\n",
    "\n",
    "la documentazione dice anche:\n",
    "\n",
    "If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are\n",
    "the minimum number of samples for each node; in altre parole, puoi scegliere questo\n",
    "valore in modo relativo alla dimensione del tuo dataset\n",
    "---\n",
    "\n",
    "max_features indica il numero di feature da considerare quando si sceglie la migliore per eseguire uno split.\n",
    "---\n",
    "ok; questo iperparametro di solito si valida in un ensemble di alberi come random forest;\n",
    "per DT puoi lasciare il valore di default\n",
    "---\n",
    "\n",
    "max_leaf_node indica il numero massimo di foglie: di volta in volta viene eseguito lo split con il maggior decremento di entropia, fino ad arrivare al numero massimo di foglie desiderato.\n",
    "---\n",
    "questo iperparametro è un po' difficile da interpretare/validare; personalmente lo lascio com'è;\n",
    "---\n",
    "\n",
    "---\n",
    "riassumendo: puoi validare la profondità; volendo, min_samples_leaf e min_samples_split\n",
    "---\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i migliori valori dei parametri sono: {'max_depth': 8, 'max_leaf_nodes': 15}\n",
      "0.9196666666666667\n",
      "0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "# Creo il modello\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# creo distribuzione dell'iperparametro\n",
    "depth_distribution = {'max_depth': poisson(mu = 10), 'max_leaf_nodes': randint(low = 5, high = 35)}\n",
    "\"\"\"\n",
    "ok usare random search, e bene provare a passare una distribuzione\n",
    "\n",
    "perché poisson con media 10? idealmente ogni valore di profondità è buono, quindi meglio\n",
    "campionare da una distribuzione uniforme\n",
    "\n",
    "ok per max_leaf_nodes, anche se come ti dicevo preferisco validare\n",
    "min_samples_leaf e min_samples_split\n",
    "\n",
    "che distrubuzione useresti per questi ultimi due iperparametri?\n",
    "\"\"\"\n",
    "\n",
    "# valido l'iperparametro\n",
    "clf = RandomizedSearchCV(estimator = tree, n_iter = 10, param_distributions = depth_distribution, n_jobs = -1, scoring = 'accuracy', cv = 5)\n",
    "\"\"\"\n",
    "n_iter = 10 sono un po' poche (specialmente per modelli più complessi di DT, con\n",
    "diversi iperparametri da validare)\n",
    "\n",
    "cosa succede se rilanci questo esperimento? ti aspetti sempre lo stesso risultato?\n",
    "a cosa è dovuto? come puoi \"fissare\" questa eventuale randomicità?\n",
    "\"\"\"\n",
    "\n",
    "# addestro il modello\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# i migliori valori dei parametri\n",
    "print(f'i migliori valori dei parametri sono: {clf.best_params_}')\n",
    "\n",
    "# valuto la accuratezza media della migliore combinazione di parametri\n",
    "tree_score = clf.best_score_\n",
    "print(f\"l'accuratezza media del miglior modello è {tree_score}\")\n",
    "                                                  \n",
    "# valuto l'accuratezza sul test set\n",
    "tree_test_score = accuracy_score(y_test, clf.predict(X_test))\n",
    "print(f\"l'accuratezza sul test set è {tree_test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    71\n",
       "0    59\n",
       "2    48\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# controllo che la precisione non sia dovuta a una classe prevalente\n",
    "\"\"\"\n",
    "accuratezza, non precisione; che differenza c'è?\n",
    "\n",
    "accuratezza = rapporto tra i casi correttamente classificati e i casi totali\n",
    "precisione = frazione dei soggetti realmente positivi tra quelli etichettati come tali\n",
    "---\n",
    "ok\n",
    "---\n",
    "\n",
    "come gestiresti un eventuale sbilanciamento tra le classi (metrica? modello?)\n",
    "\n",
    "come metriche utilizzerei sia la precision che la recall,\n",
    "o per avere un indicatore più sintetico l'F1 score.\n",
    "---\n",
    "ok; visto che il problema è multiclasse, come definiresti recall e precision?\n",
    "prova a indagare sul concetto di micro-macro-weighted average e dai un'occhiata\n",
    "alla confusion matrix\n",
    "---\n",
    "un eventuale sbilanciamento tra le classi può causare overfitting,\n",
    "per questo utilizzerei un metodo ensemble di averaging/voting che punti a\n",
    "diminuire la varianza del modello.\n",
    "---\n",
    "un eventuale sbilanciamento tra le classi, più che overfitting (= imparare\n",
    "troppo dal training set, che è solo un campione del fenomeno che stai studiando),\n",
    "fa sì che il tuo modello dia più importanza a una classe rispetto all'altra\n",
    "(o alle altre)\n",
    "\n",
    "che argomenti puoi usare per bilanciare le classi in fase di addestramento? vedi qui\n",
    "(anche se vale per tutti i modelli):\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "ultimo aspetto, la divisione in fold; la tua random search usa cv=5, dividendo i dati\n",
    "in 5 fold; come viene costruito questo split? che alternative hai?\n",
    "prova a indagare a partire dalla documentazione di random search\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "altra cosa: è necessario scalare i dati prima dell'apprendimento con DT? perché?\n",
    "\n",
    "Non è necessario scalare i dati perchè non c'è un trade off\n",
    "tra due grandezze: ogni nodo esegue lo split sulla base di una sola feature.\n",
    "Riscalando i dati si scalerebbe anche la soglia di separazione dei\n",
    "dati all'interno del nodo, ma non cambierebbe il risultato.\n",
    "---\n",
    "ok: quando splitti ogni feature viene valutata da sola, una alla volta,\n",
    "mai in combinazione con le altre\n",
    "---\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello Decision Tree fornisce già degli ottimi risultati sul test set (precisione del 92%). Tuttavia, passando ad un modello Random Forest, si potrebbe ulteriormente ridurre la varianza eccessiva del modello e quindi un leggero overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sapresti spiegare\n",
    "\n",
    "- cosa sono la varianza e il bias di un modello?\n",
    "\n",
    "varianza = variabilità delle predizioni di un modello\n",
    "bias = differenza tra la predizione media e valore target (una label nella classificazione, una misura nel caso della regressione)\n",
    "\n",
    "- come random forest lavora su questi concetti combinando modelli diversi?\n",
    "\n",
    "I modelli decision trees sono modelli molto complessi,\n",
    "---\n",
    "questo vale sempre? o dipende dai valori degli iperparametri?\n",
    "---\n",
    "quindi le predizioni presentano un'alta varianza.\n",
    "Facendo la media delle predizioni di un certo numero\n",
    "(determinato da un iperparametro) di decision trees, random forest\n",
    "riesce a ridurre questa variabilità.\n",
    "---\n",
    "ok; quindi l'obiettivo è combinare predittori ad alta varianza, con lo scopo di\n",
    "ottenere un ensemble\n",
    "- che avrà un po' di bias in più rispetto a quello dei singoli alberi\n",
    "- ma molta meno varianza, e questo dà luogo a un modello (l'ensemble) migliore\n",
    "---\n",
    "I singoli alberi sono 'modelli diversi' in quanto vengono addestrati\n",
    "ognuno su un bootstrap sample del training set (la cui creazione è\n",
    "regolata anch'essa da un iperparametro).\n",
    "---\n",
    "cos'altro c'è di random nella costruzione dei singoli alberi di una foresta?\n",
    "---\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I migliori valori degli iperparametri sono: {'max_features': 6, 'n_estimators': 109} \n",
      " La loro accuratezza media sul training set è 0.9836666666666666\n"
     ]
    }
   ],
   "source": [
    "# creo il modello\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "# creo un dizionario coi possibili valori dei parametri\n",
    "params = {'n_estimators': poisson(mu = 100), 'max_features': randint(low = 3, high = 13)}\n",
    "\n",
    "\"\"\"\n",
    "indaga meglio su quali sono gli iperparametri di random forest che vale la pena di validare;\n",
    "nel prossimo invio, spiegami il loro significato e qual è il loro effetto sul modello\n",
    "\n",
    "puoi iniziare dalla user guide di sklearn\n",
    "\n",
    "I principali iperparametri di random forest sono n_estimators e max_features.\n",
    "Il primo indica il numero di alberi nella 'foresta',\n",
    "il secondo il numero di features che vengono prese in considerazione\n",
    "per scegliere quella che splittata, massimizza il decremento di impurità ad ogni nodo.\n",
    "\n",
    "Più aumenta n_estimators meglio il modello è in grado di predire,\n",
    "ma ciò comporta un maggior tempo di calcolo.\n",
    "Dopo un certo numero di alberi il miglioramento non è più significativo.\n",
    "---\n",
    "ok; però appunto validerei dei valori grandi a piacere e non centrati intorno a un valore\n",
    "specifico (mu=100); es: [100, 200, 500, 750, 1000]\n",
    "---\n",
    "\n",
    "Più aumenta max_features più si riduce la varianza del modello,\n",
    "ma questo comporta un aumento del bias. \n",
    "---\n",
    "ok; quindi questo iperparametro rappresenta\n",
    "- un fattore di smoothing dei singoli alberi, che idealmente dovrebbero avere alta varianza/\n",
    "basso bias, cioè essere molto specializzati\n",
    "- quindi, in altre parole, \"il grado di bias che sei disposto ad inserire nei singoli alberi\"\n",
    "\n",
    "idealmente puoi validare valori da 1 a d, dove d è il numero di feature (anche se ti puoi\n",
    "fermare prima, volendo a sqrt(d) o a d/2)\n",
    "---\n",
    "\n",
    "---\n",
    "male non fa, sempre in ottica di smoothing, provare a validare anche min_samples_leaf/split\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "# valido i parametri \n",
    "clf = RandomizedSearchCV(estimator = random_forest, param_distributions = params, n_jobs =-1, scoring = 'accuracy', cv = 5, n_iter = 10)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# controllo i migliori valori dei iperparametri e la loro accuratezza\n",
    "print(f\"\"\" I migliori valori degli iperparametri sono: {clf.best_params_} \n",
    " La loro accuratezza media sul training set è {clf.best_score_}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# uso la cross-validation per calcolare la precisione del nuovo modello\n",
    "scores = cross_val_score(clf, features, target, cv = 10)\n",
    "print(f'la media della precisione è {scores.mean()}, con una deviazione standard di {scores.std()}')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "questo test non è esattamente legale; stai infatti mischiando i dati\n",
    "di training e test che hai separato prima, e li stai usando tutti insieme\n",
    "\n",
    "proviamo a ragionare su questo aspetto, che è delicato\n",
    "\n",
    "per scegliere i migliori valori degli iperparametri, e quindi il tuo\n",
    "best model, hai fatto dei test incrociati (quanti? 10), con altrettanti addestramenti;\n",
    "hai quindi usato TUTTI i dati del train per calibrare qualcosa, appunto\n",
    "il valore degli iperparametri\n",
    "\n",
    "facendo una cross validation su tutti i dati, come in questa cella, stai\n",
    "rimescolando tutto, andando a testare il tuo modello sui\n",
    "dati che hai usato, nella fase precedente, per scegliere gli\n",
    "iperparametri; il che è illegale; è come se stessi dando, indirettamente,\n",
    "una sbirciatina al futuro; ti torna?\n",
    "\n",
    "si si è chiaro, ho compreso l'errore :)\n",
    "---\n",
    "bene!\n",
    "---\n",
    "\n",
    "in altre parole: in questa cella stai effettivamente addestrando e testando su dati\n",
    "diversi, e questo è ok; ma stai usando un modello (= i suoi\n",
    "iperparametri) che hai scelto usando parte dei dati su cui adesso stai valutando\n",
    "il risultato\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "# calcolo l'accuratezza del modello\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come si può notare l'accuratezza del modello è aumentata ulteriormente. Si potrebbe anche valutare di eliminare alcune features e verificare il cambiamento nella precisione del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 96.23007113  32.4564033    8.8835039   17.69316773   9.03341188\n",
      "  76.76582416 155.29998883  18.97778387  17.85473739  88.41759919\n",
      "  77.94735094 123.55232287 166.21407675]\n",
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# guardo i punteggi delle features usando SelectKbest\n",
    "selector = SelectKBest(k = 'all')\n",
    "\"\"\"\n",
    "sapresti spiegare come funziona la procedura che hai scelto? che criterio viene\n",
    "usato per dare il punteggio alle feature?\n",
    "\n",
    "La procedura in questione seleziona le k migliori features tra quelle presenti nel training set.\n",
    "Il criterio utilizzato è una statistica test (in questo caso quella di default\n",
    "che è il test di ANOVA, in quanto adatto a task di classificazione)\n",
    "---\n",
    "ok: https://blog.minitab.com/en/adventures-in-statistics-2/understanding-analysis-of-variance-anova-and-the-f-test\n",
    "---\n",
    "\n",
    "idealmente, quando fai feature selection (e in generale per qualsiasi\n",
    "operazione di fine-tuning), dovresti usare solo i dati di training; immagina\n",
    "sempre che il test set non sia disponibile fino alla fine dell'addestramento\n",
    "\"\"\"\n",
    "\n",
    "# applico il selezionatore solo al training set, e stampo i punteggi delle feature\n",
    "selector.fit(X_train, y_train)\n",
    "print(selector.scores_)\n",
    "\n",
    "# seleziono solo le features con uno score superiore a 50\n",
    "print(len([score for score in selector.scores_ if score > 50 ]))\n",
    "\n",
    "plt.style.use('seaborn-dark')\n",
    "plt.barh(y = X_train.columns, width = selector.scores_)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nel grafico potresti ordinarle per importanza (prova anche con seaborn)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 7)\n"
     ]
    }
   ],
   "source": [
    "# creo un selezionatore delle migliori 7 features\n",
    "selector = SelectKBest(k = 7)\n",
    "\n",
    "\"\"\"\n",
    "perché le migliori sette?\n",
    "\n",
    "Dai punteggi ho notato una grande differenza tra i punteggi di alcune features\n",
    "e quelli di altre. Quindi ho usato 50 come punteggio soglia per separare\n",
    "questi due gruppi. Stampando il numero delle features che soddisfavano questo requisito,\n",
    "ho stabilito che il gruppo delle migliori features era composto da 7\n",
    "di queste (ultimo passaggio della slide precedente).\n",
    "\n",
    "ok, la soglia empirica mi torna di più del numero \"7\"\n",
    "\n",
    "invece di riaddestrare SelectKBest con k=7 puoi usare i punteggi ottenuti e\n",
    "la soglia che hai scelto come \"maschera\" per costruire X_train_new e X_test_new\n",
    "a partire da X_train e X_test\n",
    "\"\"\"\n",
    "\n",
    "# trasformo la matrice delle features originale\n",
    "X_train_new = selector.fit_transform(X_train, y_train)\n",
    "print(X_train_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I migliori valori dei parametri sono {'max_features': 3, 'n_estimators': 95} \n",
      "La loro accuratezza media è 0.9836666666666666\n"
     ]
    }
   ],
   "source": [
    "# creo un nuovo modello da addestrare sulla nuova matrice delle features\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "# creo un dizionario coi possibili valori dei parametri\n",
    "params = {'n_estimators': poisson(mu = 100), 'max_features': randint(low = 3, high = 7)}\n",
    "\"\"\"\n",
    "vedi su per i commenti sugli iperparametri\n",
    "\"\"\"\n",
    "\n",
    "# valido i parametri \n",
    "clf = RandomizedSearchCV(estimator = random_forest, param_distributions = params, n_jobs =-1, scoring = 'accuracy', cv = 5, n_iter = 10)\n",
    "\n",
    "# addestro il modello sulla nuova matrice delle features\n",
    "clf.fit(X_train_new, y_train)\n",
    "\n",
    "# controllo i migliori valori dei parametri\n",
    "print(f'''I migliori valori dei parametri sono {clf.best_params_} \n",
    "La loro accuratezza media è {clf.best_score_}''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9814814814814815"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applico la selezione anche al test set\n",
    "X_test_new = selector.fit_transform(X_test, y_test)\n",
    "\n",
    "# ricalcolo l'accuratezza del modello\n",
    "clf.score(X_test_new, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ricalcolando l'accuratezza risulta evidente che quasi tutta l'informazione necessaria al modello per la prediction è prodotta dalle migliori 7 features: nonostante siano state eliminate 5 features, la perdita della precisione è solamente dell' 1%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ok; la perdita di accuratezza :D\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le migliori 7 features sono: \n",
      "['alcohol', 'total_phenols', 'flavanoids', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
     ]
    }
   ],
   "source": [
    "wine = datasets.load_wine()\n",
    "original_features = np.array(wine.feature_names)\n",
    "features_filter = selector.get_support()\n",
    "\n",
    "\"\"\"\n",
    "occhio a non usare nomi di variabili che sono già keyword del linguaggio\n",
    "\"\"\"\n",
    "\n",
    "print('Le migliori 7 features sono: ')\n",
    "print([feature for feature in original_features[features_filter]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
